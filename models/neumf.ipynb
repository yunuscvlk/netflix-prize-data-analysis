{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c82584-3123-40ac-bfcb-0c5c2c0822e3",
   "metadata": {},
   "source": [
    "# **NeuMF for Collaborative Filtering Analysis**\n",
    "This file utilizes Neural Matrix Factorization (NeuMF) for collaborative filtering on the Netflix Prize Dataset. By leveraging matrix factorization with deep learning, the model learns user and movie embeddings to generate personalized movie recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08331f90-5613-468b-b474-f1f7abc88d1d",
   "metadata": {},
   "source": [
    "## **Data Preprocessing and Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bad762-4a2f-4318-b4f1-91cb7b166735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from d2l import mxnet as d2l\n",
    "from mxnet import gluon, np, npx\n",
    "\n",
    "npx.set_np()\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"Reads data from a CSV file and returns the data, number of unique customers, and number of unique movies.\"\"\"\n",
    "    \n",
    "    data = pd.read_csv(filename, sep=';')\n",
    "\n",
    "    num_customers = data[\"CustomerID\"].unique().shape[0]\n",
    "    num_movies = data[\"MovieID\"].unique().shape[0]\n",
    "\n",
    "    return data, num_customers, num_movies\n",
    "\n",
    "def split_data(data, test_ratio=0.2):\n",
    "    \"\"\"Splits the data into training and testing sets based on the given test ratio.\"\"\"\n",
    "    \n",
    "    mask = [True if x == 1 else False for x in np.random.uniform(0, 1, (len(data))) < 1 - test_ratio]\n",
    "    neg_mask = [not x for x in mask]\n",
    "    train_data, test_data = data[mask], data[neg_mask]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "def load_data(data):\n",
    "    \"\"\"Loads customer, movie, and rating data from a DataFrame into NumPy arrays.\"\"\"\n",
    "    \n",
    "    customers, movies, rates = [], [], []\n",
    "\n",
    "    for line in data.itertuples():\n",
    "        customer_index, movie_index, rate = int(line[1] - 1), int(line[2] - 1), int(line[3])\n",
    "        customers.append(customer_index)\n",
    "        movies.append(movie_index)\n",
    "        rates.append(rate)\n",
    "\n",
    "    return np.array(customers), np.array(movies), np.array(rates)\n",
    "\n",
    "def split_and_load(filename, test_ratio=0.2, batch_size=256):\n",
    "    \"\"\"Combines data reading, splitting, and loading into a single function, returning data loaders and metadata.\"\"\"\n",
    "    \n",
    "    data, num_customers, num_movies = read_data(filename)\n",
    "    train_data, test_data = split_data(data, test_ratio)\n",
    "    train_customers, train_movies, train_rates = load_data(train_data)\n",
    "    test_customers, test_movies, test_rates = load_data(test_data)\n",
    "\n",
    "    train_set = gluon.data.ArrayDataset(train_customers, train_movies, train_rates)\n",
    "    test_set = gluon.data.ArrayDataset(test_customers, test_movies, test_rates)\n",
    "\n",
    "    train_iter = gluon.data.DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "    test_iter = gluon.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "    return num_customers, num_movies, train_iter, test_iter\n",
    "\n",
    "filename, test_ratio, batch_size = '../data/random_100k_sample.csv', 0.2, 256\n",
    "num_customers, num_movies, train_iter, test_iter = split_and_load(filename, test_ratio, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca22a522-aa03-43e4-a6aa-2d5fff0862bc",
   "metadata": {},
   "source": [
    "## **Defining the Matrix Factorization Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6755c2e8-3d51-4e7d-9cb0-e5ae0c5b2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "\n",
    "class MatrixFactorization(nn.Block):\n",
    "    \"\"\"Defines a matrix factorization model using embedding layers for customers and movies.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_customers, num_movies, num_factors, **kwargs):\n",
    "        super(MatrixFactorization, self).__init__(**kwargs)\n",
    "        \n",
    "        self.customer_embedding = nn.Embedding(num_customers, num_factors)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, num_factors)\n",
    "        self.customer_bias = nn.Embedding(num_customers, 1)\n",
    "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
    "\n",
    "    def forward(self, customers, movies):\n",
    "        \"\"\"Forward pass of the model, calculating predicted ratings.\"\"\"\n",
    "        \n",
    "        customer_vecs = self.customer_embedding(customers)\n",
    "        movie_vecs = self.movie_embedding(movies)\n",
    "        \n",
    "        preds = (\n",
    "            (customer_vecs * movie_vecs).sum(axis=1) +\n",
    "            self.customer_bias(customers).squeeze() +\n",
    "            self.movie_bias(movies).squeeze()\n",
    "        )\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e46d4d-0d00-417c-a795-b1d92c0a09b4",
   "metadata": {},
   "source": [
    "## **Defining the Training Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3b2913-8c75-440f-bd3a-dca3273ab667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd, nd, init\n",
    "from mxnet.gluon import Trainer, loss as gloss\n",
    "\n",
    "def train_recommender(net, train_iter, num_epochs, lr, wd, ctx):\n",
    "    \"\"\"Trains a recommender model using the given network, data iterators, and hyperparameters.\"\"\"\n",
    "    \n",
    "    net.initialize(ctx=ctx, force_reinit=True, init=init.Normal(0.01))\n",
    "    \n",
    "    trainer = Trainer(net.collect_params(), 'adam', {'learning_rate': lr, 'wd': wd})\n",
    "    loss = gloss.L2Loss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = d2l.Accumulator(3)\n",
    "\n",
    "        for i, (customers, movies, rates) in enumerate(train_iter):\n",
    "            customers, movies, rates = customers.as_in_ctx(ctx), movies.as_in_ctx(ctx), rates.as_in_ctx(ctx)\n",
    "\n",
    "            with autograd.record():\n",
    "                preds = net(customers, movies)\n",
    "                l = loss(preds, rates)\n",
    "                \n",
    "            l.backward()\n",
    "            trainer.step(batch_size=rates.shape[0])\n",
    "            metric.add(l.sum().item(), rates.size, 1)\n",
    "\n",
    "        train_rmse = nd.sqrt(nd.array([metric[0]]) / nd.array([metric[1]]))\n",
    "        print(f'epoch {epoch + 1}, train RMSE: {train_rmse.asscalar():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a47f1c6-6d20-4a0c-a670-6a3260bd0a69",
   "metadata": {},
   "source": [
    "## **Matrix Factorization Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afdb97f7-6f0b-4ed3-891e-7c9b40064591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train RMSE: 1.4812\n",
      "epoch 2, train RMSE: 0.8118\n",
      "epoch 3, train RMSE: 0.7567\n",
      "epoch 4, train RMSE: 0.7383\n",
      "epoch 5, train RMSE: 0.7281\n",
      "epoch 6, train RMSE: 0.7210\n",
      "epoch 7, train RMSE: 0.7151\n",
      "epoch 8, train RMSE: 0.7097\n",
      "epoch 9, train RMSE: 0.7058\n",
      "epoch 10, train RMSE: 0.7017\n",
      "epoch 11, train RMSE: 0.6986\n",
      "epoch 12, train RMSE: 0.6961\n",
      "epoch 13, train RMSE: 0.6938\n",
      "epoch 14, train RMSE: 0.6915\n",
      "epoch 15, train RMSE: 0.6898\n",
      "epoch 16, train RMSE: 0.6882\n",
      "epoch 17, train RMSE: 0.6870\n",
      "epoch 18, train RMSE: 0.6861\n",
      "epoch 19, train RMSE: 0.6851\n",
      "epoch 20, train RMSE: 0.6843\n"
     ]
    }
   ],
   "source": [
    "ctx = d2l.try_gpu()\n",
    "num_factors = 20\n",
    "net = MatrixFactorization(num_customers, num_movies, num_factors)\n",
    "num_epochs, lr, wd, batch_size = 20, 0.005, 0, 256\n",
    "train_recommender(net, train_iter, num_epochs, lr, wd, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46587db1-4f77-4c87-bcdf-c0a2c4fa5baf",
   "metadata": {},
   "source": [
    "## **RMSE Calculation for Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9eca5fc-2023-4a08-a8a8-4b052dc961fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.7563\n"
     ]
    }
   ],
   "source": [
    "from mxnet import nd\n",
    "\n",
    "def evaluate_rmse(net, data_iter, ctx):\n",
    "    \"\"\"Evaluates the Root Mean Squared Error (RMSE) of a given network on a dataset.\"\"\"\n",
    "    \n",
    "    loss = gluon.loss.L2Loss()\n",
    "    metric = d2l.Accumulator(2)\n",
    "\n",
    "    for i, (customers, movies, rates) in enumerate(data_iter):\n",
    "        customers, movies, rates = customers.as_in_ctx(ctx), movies.as_in_ctx(ctx), rates.as_in_ctx(ctx)\n",
    "        preds = net(customers, movies)\n",
    "        l = loss(preds, rates)\n",
    "        metric.add(l.sum().item(), rates.size)\n",
    "\n",
    "    rmse = nd.sqrt(nd.array(metric[0]) / nd.array(metric[1]))\n",
    "    return rmse.asscalar()\n",
    "\n",
    "test_rmse = evaluate_rmse(net, test_iter, ctx)\n",
    "print(f'Test RMSE: {test_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae296fc-3577-419b-8b5e-1bf83e37bc21",
   "metadata": {},
   "source": [
    "## **Movie Recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a438273-4033-4f0c-82ca-5aa3b3ed9cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies for customer 44285: [9300, 3997, 5976, 6543, 1330, 1993, 7627, 469, 8001, 249]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import mxnet as mx\n",
    "\n",
    "def recommend_movies(net, num_customers, num_movies, ctx, num_recommendations=10):\n",
    "    \"\"\"Generates movie recommendations for a random customer based on the trained model.\"\"\"\n",
    "    \n",
    "    customer_id = random.randint(0, num_customers - 1)\n",
    "\n",
    "    movie_ids = np.arange(num_movies)\n",
    "    customers = np.full_like(movie_ids, customer_id)\n",
    "    movies = movie_ids\n",
    "\n",
    "    customers = mx.np.array(customers, ctx=ctx)\n",
    "    movies = mx.np.array(movies, ctx=ctx)\n",
    "\n",
    "    preds = net(customers, movies)\n",
    "    pred_with_movie_id = list(zip(preds.asnumpy(), movie_ids))\n",
    "    pred_with_movie_id.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    recommended_movies = [movie_id for _, movie_id in pred_with_movie_id[:num_recommendations]]\n",
    "    return customer_id, recommended_movies\n",
    "\n",
    "customer_id, recommended_movies = recommend_movies(net, num_customers, num_movies, ctx, 10)\n",
    "print(f\"Recommended movies for customer {customer_id}: {recommended_movies}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (netflix-prize-data)",
   "language": "python",
   "name": "netflix-prize-data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
