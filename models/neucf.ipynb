{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "n2lWBfZTBmXD"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHHq12WdBlaD",
    "outputId": "0b24e208-ebc5-43eb-82b8-580f490fae7c"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/random_100k_sample.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K0Ci_7FsBITe"
   },
   "outputs": [],
   "source": [
    "user_id_map = { user_id: idx for idx, user_id in enumerate(data['CustomerID'].unique()) }\n",
    "movie_id_map = { movie_id: idx for idx, movie_id in enumerate(data['MovieID'].unique()) }\n",
    "\n",
    "data['user'] = data['CustomerID'].map(user_id_map)\n",
    "data['movie'] = data['MovieID'].map(movie_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6NCO0NHJFcbQ"
   },
   "outputs": [],
   "source": [
    "x = data[['user', 'movie']].values\n",
    "y = data['Rate'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2fCMwU0hFmDm"
   },
   "outputs": [],
   "source": [
    "num_users = len(user_id_map)\n",
    "num_movies = len(movie_id_map)\n",
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6B5_JRbF8q0"
   },
   "source": [
    "## User and movie embedding\n",
    "Here, users and movies are represented in a vector dimension of a certain size. Then, the embedding vector for each user or movie is made suitable as input to dense layers (in short, flat). Dense layers work with one-dimensional arrays. Flattening is a must, the model cannot send this data to dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EeqrYFG1F-AK"
   },
   "source": [
    "user_input = tf.keras.layers.Input(shape=(1,), name='user_input')\n",
    "movie_input = tf.keras.layers.Input(shape=(1,), name='movie_input')\n",
    "\n",
    "user_embedding = tf.keras.layers.Embedding(input_dim=num_users, output_dim=embedding_size, name='user_embedding')(user_input)\n",
    "movie_embedding = tf.keras.layers.Embedding(input_dim=num_movies, output_dim=embedding_size, name='movie_embedding')(movie_input)\n",
    "\n",
    "user_flatten = tf.keras.layers.Flatten()(user_embedding)\n",
    "movie_flatten = tf.keras.layers.Flatten()(movie_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0pe_DtTIhNN"
   },
   "source": [
    "## Concatenation\n",
    "Here, the user and film vectors prepared for the dense layers are combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UzjKhpdnIguC"
   },
   "outputs": [],
   "source": [
    "concat = tf.keras.layers.Concatenate()([user_flatten, movie_flatten])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iR-kC197JNCa"
   },
   "source": [
    "## Feature Learning with Fully Connected Layers\n",
    "Fully connected layers are created here. In the first layer, the number of neurons is 128. In other words, 128 different features are tried to be learned. The ReLu activation function brings the negatives closer to zero and leaves the positives as they are. Non-linear relationships are learned. Concat is the combination of the user and movie vectors we created above. Our first layer starts the learning process from here. In the 2nd layer; it adds 64 more features to the 128 features learned in the first layer. The dense1 at the end shows that it uses the features of the previous layer. In the 3rd layer, the learning process is completed by taking the output of the 2nd layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "P4kDLVoaJMBh"
   },
   "outputs": [],
   "source": [
    "dense1 = tf.keras.layers.Dense(64, activation='relu', name='dense1')(concat)\n",
    "dense2 = tf.keras.layers.Dense(32, activation='relu', name='dense2')(dense1)\n",
    "dense3 = tf.keras.layers.Dense(32, activation='relu', name='dense3')(dense2)\n",
    "output = tf.keras.layers.Dense(1, activation='linear', name='output')(dense3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaGaDL2aM8Jh"
   },
   "source": [
    "Here the model is created. The inputs are the user and movie inputs, which are the information the model will receive, and the output is the user's predicted score to be predicted. Adam optimization algorithm was used. The model's error was measured with MSE. (RMSE will be calculated by taking the square of all values ​​while calculating the overall accuracy.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "k24LPxr4M8bk",
    "outputId": "048e8d58-5cf1-4bfb-831b-87a4a5899e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " movie_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 50)                3863900   ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " movie_embedding (Embedding  (None, 1, 50)                465050    ['movie_input[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 50)                   0         ['user_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 50)                   0         ['movie_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 100)                  0         ['flatten[0][0]',             \n",
      "                                                                     'flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense1 (Dense)              (None, 64)                   6464      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense2 (Dense)              (None, 32)                   2080      ['dense1[0][0]']              \n",
      "                                                                                                  \n",
      " dense3 (Dense)              (None, 32)                   1056      ['dense2[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 1)                    33        ['dense3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4338583 (16.55 MB)\n",
      "Trainable params: 4338583 (16.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=[user_input, movie_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeybxylqO4ON"
   },
   "source": [
    "The training of the model starts here. x_train is our training set. [x_train[:, 0], x_train[:, 1]] Here the movie and user columns are separated from each other. These two columns are the input data from which the model will receive user and movie information. y_train contains the target data that the model will try to predict. In this case, the target value will be the score that the user will give to the movie. validation_data is the validation step. The performance of the model is measured with data that it has not seen before in the part where it is still learning. Epoch is the number of times the model makes a full transformation on the training data set. Since 10 epochs are specified here, the model will work on the training data 10 times. Batch size is actually the number of iterations. In other words, it is the number of data samples to be presented to the model. verbose is how much detailed information will be given in the output of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLM7AVq3O3Uk",
    "outputId": "620052f7-25a3-4e58-a606-b96f0704645f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 101s 80ms/step - loss: 1.4646 - mse: 1.4646 - val_loss: 1.0936 - val_mse: 1.0936\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 93s 74ms/step - loss: 0.6279 - mse: 0.6279 - val_loss: 1.2007 - val_mse: 1.2007\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 101s 81ms/step - loss: 0.3831 - mse: 0.3831 - val_loss: 1.2804 - val_mse: 1.2804\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 89s 71ms/step - loss: 0.2174 - mse: 0.2174 - val_loss: 1.2349 - val_mse: 1.2349\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 88s 70ms/step - loss: 0.1253 - mse: 0.1253 - val_loss: 1.2324 - val_mse: 1.2324\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 89s 71ms/step - loss: 0.0952 - mse: 0.0952 - val_loss: 1.2542 - val_mse: 1.2542\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 97s 77ms/step - loss: 0.0759 - mse: 0.0759 - val_loss: 1.2608 - val_mse: 1.2608\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 98s 79ms/step - loss: 0.0650 - mse: 0.0650 - val_loss: 1.2606 - val_mse: 1.2606\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 87s 70ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 1.2507 - val_mse: 1.2507\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 85s 68ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 1.2752 - val_mse: 1.2752\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [x_train[:, 0], x_train[:, 1]], y_train,\n",
    "    validation_data=([x_test[:, 0], x_test[:, 1]], y_test),\n",
    "    epochs=10, batch_size=64, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1AXxbvcRnGu"
   },
   "source": [
    "# Model Prediction and Evaluation (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dl25lpGc_4hF",
    "outputId": "e1edf210-20ed-4f7b-a874-ee8825847da1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step\n",
      "Root Mean Squared Error (RMSE): 1.1292402903878196\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([x_test[:, 0], x_test[:, 1]])\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (netflix-prize-data)",
   "language": "python",
   "name": "netflix-prize-data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
